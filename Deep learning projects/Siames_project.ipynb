{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "FMUP1UpJhHFS"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-09 20:54:22.973420: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-08-09 20:54:22.974903: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-08-09 20:54:23.004283: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-08-09 20:54:23.005362: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-09 20:54:23.527838: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# imports :\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import tqdm # for the progress line\n",
    "\n",
    "import glob # for the paths\n",
    "\n",
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: kaggle in /home/abdalrahman/.local/lib/python3.8/site-packages (1.6.17)\n",
      "Requirement already satisfied: six>=1.10 in /usr/lib/python3/dist-packages (from kaggle) (1.14.0)\n",
      "Requirement already satisfied: certifi>=2023.7.22 in /home/abdalrahman/.local/lib/python3.8/site-packages (from kaggle) (2024.7.4)\n",
      "Requirement already satisfied: python-dateutil in /home/abdalrahman/.local/lib/python3.8/site-packages (from kaggle) (2.8.2)\n",
      "Requirement already satisfied: requests in /home/abdalrahman/.local/lib/python3.8/site-packages (from kaggle) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /home/abdalrahman/.local/lib/python3.8/site-packages (from kaggle) (4.66.2)\n",
      "Requirement already satisfied: python-slugify in /home/abdalrahman/.local/lib/python3.8/site-packages (from kaggle) (8.0.4)\n",
      "Requirement already satisfied: urllib3 in /usr/lib/python3/dist-packages (from kaggle) (1.25.8)\n",
      "Requirement already satisfied: bleach in /home/abdalrahman/.local/lib/python3.8/site-packages (from kaggle) (6.1.0)\n",
      "Requirement already satisfied: webencodings in /home/abdalrahman/.local/lib/python3.8/site-packages (from bleach->kaggle) (0.5.1)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /home/abdalrahman/.local/lib/python3.8/site-packages (from python-slugify->kaggle) (1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/abdalrahman/.local/lib/python3.8/site-packages (from requests->kaggle) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->kaggle) (2.8)\n"
     ]
    }
   ],
   "source": [
    "! pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘/home/abdalrahman/.kaggle’: File exists\n"
     ]
    }
   ],
   "source": [
    "# if we wnat to read dataset from kaggle directly , first put file kaggle.json\n",
    "!mkdir ~/.kaggle\n",
    "!cp kaggle.json ~/.kaggle\n",
    "!chmod 600 ~/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/jessicali9530/celeba-dataset\n",
      "License(s): other\n",
      "Downloading celeba-dataset.zip to /home/abdalrahman/Documents/DataScienc & Machine learning/Deep learning &Artifical Neural Network/siames_project\n",
      "100%|██████████████████████████████████████| 1.33G/1.33G [20:32<00:00, 2.05MB/s]\n",
      "100%|██████████████████████████████████████| 1.33G/1.33G [20:32<00:00, 1.16MB/s]\n"
     ]
    }
   ],
   "source": [
    "!kaggle datasets download -d jessicali9530/celeba-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unzip:  cannot find or open /content/celeba-dataset.zip, /content/celeba-dataset.zip.zip or /content/celeba-dataset.zip.ZIP.\n"
     ]
    }
   ],
   "source": [
    "!unzip /content/celeba-dataset.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "1GL0hec-9iRB"
   },
   "outputs": [],
   "source": [
    "def make_pair(folder_path):\n",
    "\n",
    "  files_list=glob.glob(folder_path+'/*.jpg') # to pahs of the images\n",
    "\n",
    "  file_list1 = []\n",
    "  file_list2 = []\n",
    "\n",
    "  target_list=[]\n",
    "\n",
    "  for path in tqdm.tqdm(files_list):\n",
    "\n",
    "      file_list1.append(path)\n",
    "      file_list2.append(path)\n",
    "\n",
    "      target_list.append(1)\n",
    "\n",
    "      while True:\n",
    "         n=np.random.randint(low=0 ,high=len(files_list))\n",
    "\n",
    "         if files_list[n] != path:\n",
    "\n",
    "            file_list1.append(path)\n",
    "            file_list2.append(files_list[n])\n",
    "            target_list.append(0)\n",
    "            break\n",
    "  data_dic={\n",
    "      \"image_1\":file_list1,\n",
    "      \"image_2\":file_list2,\n",
    "      \"label\":target_list\n",
    "      }\n",
    "\n",
    "  dataset=pd.DataFrame(data=data_dic)\n",
    "\n",
    "\n",
    "  return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 441
    },
    "id": "qh0g96Pz9vr2",
    "outputId": "28471498-677e-4957-ea8b-dc284f95dfec"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_1</th>\n",
       "      <th>image_2</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [image_1, image_2, label]\n",
       "Index: []"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=make_pair('/content/img_align_celeba/img_align_celeba').iloc[:10000]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "spNYEVdV99mE",
    "outputId": "a8296897-4118-4a0b-a692-95aacb8806a3"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "With n_samples=0, test_size=0.1 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train,test\u001b[38;5;241m=\u001b[39m\u001b[43mmodel_selection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_test_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mstratify\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlabel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m train\u001b[38;5;241m.\u001b[39mshape,test\u001b[38;5;241m.\u001b[39mshape\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/model_selection/_split.py:2175\u001b[0m, in \u001b[0;36mtrain_test_split\u001b[0;34m(test_size, train_size, random_state, shuffle, stratify, *arrays)\u001b[0m\n\u001b[1;32m   2172\u001b[0m arrays \u001b[38;5;241m=\u001b[39m indexable(\u001b[38;5;241m*\u001b[39marrays)\n\u001b[1;32m   2174\u001b[0m n_samples \u001b[38;5;241m=\u001b[39m _num_samples(arrays[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m-> 2175\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m \u001b[43m_validate_shuffle_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2176\u001b[0m \u001b[43m                                          \u001b[49m\u001b[43mdefault_test_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.25\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2178\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m shuffle \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m   2179\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stratify \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/model_selection/_split.py:1857\u001b[0m, in \u001b[0;36m_validate_shuffle_split\u001b[0;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[1;32m   1854\u001b[0m n_train, n_test \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(n_train), \u001b[38;5;28mint\u001b[39m(n_test)\n\u001b[1;32m   1856\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_train \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 1857\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1858\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWith n_samples=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, test_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m and train_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, the \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1859\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresulting train set will be empty. Adjust any of the \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1860\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124maforementioned parameters.\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_samples, test_size,\n\u001b[1;32m   1861\u001b[0m                                             train_size)\n\u001b[1;32m   1862\u001b[0m     )\n\u001b[1;32m   1864\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m n_train, n_test\n",
      "\u001b[0;31mValueError\u001b[0m: With n_samples=0, test_size=0.1 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."
     ]
    }
   ],
   "source": [
    "train,test=model_selection.train_test_split(df,test_size=0.1,random_state=42,stratify=df[\"label\"])\n",
    "train.shape,test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xD3WB_FF-Bxs"
   },
   "outputs": [],
   "source": [
    "def read_image(x,y):\n",
    "    x1,x2=x\n",
    "\n",
    "    x1=tf.io.read_file(x1)\n",
    "    x1=tf.image.decode_jpeg(x1,channels=3)\n",
    "    x1=tf.image.convert_image_dtype(x1,tf.float32)\n",
    "    x1=tf.image.resize(x1,(244,244))\n",
    "\n",
    "\n",
    "    x2=tf.io.read_file(x2)\n",
    "    x2=tf.image.decode_jpeg(x2,channels=3)\n",
    "    x2=tf.image.convert_image_dtype(x2,tf.float32)\n",
    "    x2=tf.image.resize(x2,(244,244))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    return (x1,x2),y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r51VHx4R-Xlw"
   },
   "outputs": [],
   "source": [
    "def train_preprocessing(x,y):\n",
    "\n",
    "    x1,x2=x\n",
    "\n",
    "    x1=tf.image.random_brightness(x1,max_delta=32.0/255.0)\n",
    "    x1=tf.image.random_flip_left_right(x1)\n",
    "    x1=tf.image.random_saturation(x1,lower=0.5,upper=1.5)\n",
    "\n",
    "\n",
    "    x2=tf.image.random_brightness(x2,max_delta=32.0/255.0)\n",
    "    x2=tf.image.random_flip_left_right(x2)\n",
    "    x2=tf.image.random_flip_up_down(x2)\n",
    "    x2=tf.image.random_saturation(x2,lower=0.5,upper=1.5)\n",
    "    return (x1,x2),y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lC4FUahB-xI6"
   },
   "outputs": [],
   "source": [
    "def dataset_creater(x1,x2,y,batch_size=32,training=False):\n",
    "    data=tf.data.Dataset.from_tensor_slices(((x1,x2),y))\n",
    "\n",
    "    data=data.shuffle(1028) #  mean to take every 1028 elemens at once\n",
    "\n",
    "    data=data.map(read_image,num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "    if training:\n",
    "\n",
    "        data=data.map(train_preprocessing,num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "\n",
    "        data=data.batch(batch_size)\n",
    "\n",
    "        data=data.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ypJcT5Gv-xLI"
   },
   "outputs": [],
   "source": [
    "train_dataset=dataset_creater(train.image_1,train.image_2,train.label,training=True)\n",
    "test_dataset=dataset_creater(test.image_1,test.image_2,test.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "25wuQFac-xN7",
    "outputId": "6c01d51e-a29b-4edc-b7b0-41317e8c8621"
   },
   "outputs": [],
   "source": [
    "n=30\n",
    "f={\"size\":30,\"color\":\"red\"}\n",
    "plt.figure(figsize=(50,5))\n",
    "\n",
    "for x,y in train_dataset.take(1):\n",
    "\n",
    "    x1,x2=x\n",
    "\n",
    "    for i in range(n):\n",
    "\n",
    "        plt.subplot(2,n,i+1)\n",
    "        plt.title(f'{y[i]}',fontdict=f)\n",
    "        plt.imshow(tf.squeeze(x1[i]))\n",
    "        plt.gray()\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "\n",
    "        plt.subplot(2,n,n+i+1)\n",
    "        plt.imshow(tf.squeeze(x2[i]))\n",
    "        plt.gray()\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UYGz-yfz_D8P",
    "outputId": "9ecda27f-196e-411d-c621-f99e3d0788d7"
   },
   "outputs": [],
   "source": [
    "cnn_model=tf.keras.applications.densenet.DenseNet121(\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    input_shape=(244,244,3)\n",
    "\n",
    ")\n",
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_u3XvLtu_Llw",
    "outputId": "0b9de04c-ff1f-4673-d7eb-ae5da2ec867b"
   },
   "outputs": [],
   "source": [
    "cnn_model.trainable=False\n",
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zQTjljGO_dh2",
    "outputId": "e30306c6-8451-445b-ae02-e9152a1b1b2b"
   },
   "outputs": [],
   "source": [
    "class SiameseModel(tf.keras.Model):\n",
    "  def __init__(self, cnn_model):\n",
    "      super(SiameseModel, self).__init__()\n",
    "\n",
    "      self.cnn_model = cnn_model\n",
    "      self.d1 = tf.keras.layers.Dense(512, use_bias=False)\n",
    "      self.bn1 = tf.keras.layers.BatchNormalization()\n",
    "      self.d2 = tf.keras.layers.Dense(128, use_bias=False)\n",
    "      self.bn2 = tf.keras.layers.BatchNormalization()\n",
    "      self.out = tf.keras.layers.Dense(units=1, activation=tf.nn.sigmoid)\n",
    "\n",
    "  def call(self, inputs):\n",
    "    x1, x2 = inputs\n",
    "    x1 = self.cnn_model(x1)\n",
    "    x1 = tf.keras.layers.GlobalAveragePooling2D()(x1)\n",
    "    x2 = self.cnn_model(x2)\n",
    "    x2 = tf.keras.layers.GlobalAveragePooling2D()(x2)\n",
    "\n",
    "    x = tf.keras.layers.concatenate([x1, x2])\n",
    "    x = self.d1(x)\n",
    "    x = self.bn1(x)\n",
    "    x = tf.nn.leaky_relu(x)\n",
    "    x = self.d2(x)\n",
    "    x = self.bn2(x)\n",
    "    x = tf.nn.leaky_relu(x)\n",
    "    output = self.out(x)\n",
    "    return output\n",
    "\n",
    "  def build_model(self, dim=[244,244,3]):\n",
    "    x = (tf.keras.layers.Input(dim), tf.keras.layers.Input(dim))\n",
    "    return tf.keras.Model(inputs=[x], outputs=[self.call(x)])\n",
    "\n",
    "\n",
    "model = SiameseModel(cnn_model)\n",
    "model.build_model(dim=[244,244,3]).summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 926
    },
    "id": "k47vtX5S_6hc",
    "outputId": "273799f2-6515-494e-d3d9-1fd58997cbbb"
   },
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model.build_model(dim=[244,244,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nAYCcpnwAEoY"
   },
   "outputs": [],
   "source": [
    "model.compile('adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-VLkQ5YPALxA",
    "outputId": "d9088ada-6b9d-48ff-9e20-4d8677775381"
   },
   "outputs": [],
   "source": [
    "model.fit(train_dataset,batch_size=32,epochs=6,validation_data=test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 237
    },
    "id": "pG58HL11AQY-",
    "outputId": "5fe1ccc4-7497-405f-e91c-9d88f85c6c7a"
   },
   "outputs": [],
   "source": [
    "df=pd.DataFrame(model.history.history)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 449
    },
    "id": "a0T4nLwDB8Fc",
    "outputId": "8836c380-a7a1-454f-8af2-c87034bff2b4"
   },
   "outputs": [],
   "source": [
    "df.plot()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
