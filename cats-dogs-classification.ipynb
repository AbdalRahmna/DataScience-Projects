{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8208729,"sourceType":"datasetVersion","datasetId":4499580}],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/abdalrhamnhebishy/cats-dogs-classification?scriptVersionId=191060770\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"from IPython.core.display import HTML\n# Apply styles globally within the notebook\nHTML('''\n<style>\n  h2 {\n    font-size: var(--jp-content-font-size4);\n    background-color: #FF0000 ;\n    color: yellow;\n    display: flex;\n    align-items: center;\n    justify-content: center;\n    padding: 10px 41px;\n    top: 10px;\n    position: relative;\n    border-radius: 10px 50px 10px 50px;\n}\n\nimg {       /* flex-grow: 1; */\n            /* flex-shrink: 1; */\n            border-radius: 150px 70px 150px 70px;\n            border: 10px solid #eee;\n            display: flex;\n            align-items: center;\n            justify-content: center;\n            transition: box-shadow 0.3s ease; /* Add a transition for a smooth effect */\n        }\n\n       img:active {\n          box-shadow: 0 10px 20px rgba(255, 255, 0, 0.5), 0 6px 6px rgba(215, 215, 0, 0.5);\n        }\n</style>\n''')","metadata":{"execution":{"iopub.status.busy":"2024-08-03T17:52:57.700526Z","iopub.execute_input":"2024-08-03T17:52:57.700932Z","iopub.status.idle":"2024-08-03T17:52:57.742185Z","shell.execute_reply.started":"2024-08-03T17:52:57.700901Z","shell.execute_reply":"2024-08-03T17:52:57.740915Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Simple Introduce :\n\n* This unstructured Data loaded from Kaggle . \n\n* I used Deep learning Techniques by using tensorflow pkgs .\n\n* I divide Data into train set & validatio set after loading the data.\n\n* I used ImageDataGenerator for preprocessing the Data .","metadata":{}},{"cell_type":"markdown","source":"## About Dataset: \n\n* The Cats and Dogs Classification dataset is a widely used benchmark dataset in the field of computer vision.\n\n* It consists of thousands of images of cats and dogs, with each image labeled as either a cat or a dog.\n\n* This dataset serves as a fundamental resource for training and evaluating machine learning models for image classification tasks.\n\n* Researchers and practitioners leverage this dataset to develop and test algorithms that can accurately distinguish between images of cats and dogs, contributing to advancements in computer vision technology.\n\n\n\n","metadata":{}},{"cell_type":"markdown","source":"## imports :","metadata":{}},{"cell_type":"code","source":"# imports :\nimport os\nimport pandas as pd\nimport numpy as np \nimport matplotlib.pyplot as plt \nimport tensorflow as tf \nfrom tensorflow.keras import Sequential \nfrom tensorflow.keras import models\nfrom tensorflow.keras.layers import Dense , Flatten , Conv2D ,MaxPooling2D\nfrom tensorflow .keras.preprocessing.image import ImageDataGenerator","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## preparing & loading the data :","metadata":{}},{"cell_type":"code","source":"# Dowanload the data (cat & dogs):\n!wget https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# to unzip the file:\n!unzip cats_and_dogs_filtered.zip","metadata":{"scrolled":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_dataset(path):\n  images_path=[]\n  images_label=[]\n  for dir in os.listdir(path):\n    for file in os.listdir(os.path.join(path, dir)):\n      images_path.append(os.path.join(path, dir, file))\n      image_label = 0 if dir==\"cats\" else 1\n      images_label.append(image_label)\n  return images_path, images_label\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_train,label_train=create_dataset(\"cats_and_dogs_filtered/train\")\nimage_test,label_test=create_dataset(\"cats_and_dogs_filtered/validation\")\nprint(f\"image_train_shape:{np.shape(image_train)}\\n label_train_shape:{np.shape(label_train)}\")\nprint(f\"image_test_shape:{np.shape(image_test)}\\n label_test_shape:{np.shape(label_test)}\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_train[1:10]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"label_train[2]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##  Agumention :","metadata":{}},{"cell_type":"code","source":"# function that read the image & conver into jpeg:\n\ndef get_image_tensor_from_path(image_path,label):\n    image=tf.io.read_file(image_path)\n    image=tf.image.decode_jpeg(image)\n    image=tf.image.convert_image_dtype(image,tf.float32)\n    image=tf.image.resize(image,(244,244))\n\n\n    return image , label","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# function to change from brightness or reloation of the image :\ndef agument(image,label):\n    image=tf.image.random_brightness(image,max_delta=32.0/255.0) # change from brightness of image\n\n    image=tf.image.random_flip_left_right(image) # change from position of image\n\n    image=tf.image.random_flip_up_down(image)\n\n    image=tf.image.random_saturation(image,lower=500000,upper=1000000)      # to change preentage of color in image\n\n\n    return image , label","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def cd_dataset(x,y,batch_size=32,training=False):\n    data=tf.data.Dataset.from_tensor_slices((x,y))\n\n    data=data.map(get_image_tensor_from_path,num_parallel_calls=tf.data.experimental.AUTOTUNE)\n\n    if training:\n\n        data=data.map(agument,num_parallel_calls=tf.data.experimental.AUTOTUNE)\n\n        data=data.shuffle(2000)\n\n        data=data.batch(batch_size)\n\n        data=data.prefetch(tf.data.experimental.AUTOTUNE)\n\n        return data","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_dataset=cd_dataset(image_train,label_train,training=True)\ntest_dataset=cd_dataset(image_test,label_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_names=[\"cat\",\"dog\"]\n\nfor x,y in train_dataset.take(1):\n\n    plt.figure(figsize=(10,10))\n\n    for i in range (25):\n\n        plt.subplot(5,5,i+1)\n        plt.imshow(x[i])\n\n        plt.xticks([])\n        plt.yticks([])\n\n        plt.xlabel(class_names[y[i]])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Data  Preprocessing :","metadata":{}},{"cell_type":"code","source":"# preprocessing the data :\ndef reshape_and_normalize(images):\n     # reshape :\n    images=images.reshape(images.reshape[0],images.reshape[1],images.reshape[2],1)\n    \n    #Normalize :\n    images=images/255\n    return images\n\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Data Generator :\ntrain_dir = \"cats_and_dogs_filtered/train\"\ntrain_datagen = ImageDataGenerator(rescale=1/255)\ntrain_generator = train_datagen.flow_from_directory(\n    train_dir,\n    target_size=(300, 300),\n    batch_size=128,\n    class_mode='binary' \n)\n\nvalidation_dir=\"cats_and_dogs_filtered/validation\"\ntest_datagen = ImageDataGenerator(rescale=1/255)\ntest_generator = test_datagen.flow_from_directory(\n    validation_dir,\n    target_size=(300, 300),\n    batch_size=128,\n    class_mode='binary' \n)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Bulding Model :","metadata":{}},{"cell_type":"code","source":"# Bulding the model :\n\nmodel=tf.keras.models.Sequential([\n    Conv2D(16,(3,3),activation=\"relu\",input_shape=(300,300,3)),\n    MaxPooling2D(2,2),\n    Conv2D(32,(3,3),activation=\"relu\"),\n    MaxPooling2D(2,2),\n    Conv2D(64,(3,3),activation=\"relu\"),\n    MaxPooling2D(2,2),\n    Conv2D(128,(3,3),activation=\"relu\"),\n    MaxPooling2D(2,2),\n    Flatten(),\n    Dense(512,activation=\"relu\"),\n    Dense(1,activation=\"sigmoid\"),\n        ])\nmodel.summary()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Callback function:\n\nclass mycallback(tf.keras.callbacks.Callback):\n\n    def one_epoch_end(self,epoch,logs={}):\n        if(logs.get(\"accuracy\")>0.995):\n            print(\"/n Stop trining :\")\n            self.model.stop_training=True","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# RMSprop optimizer:\n\nfrom tensorflow.keras.optimizers import RMSprop\n\nmodel.compile(\n    \n    loss='binary_crossentropy',\n    optimizer=RMSprop(lr=0.001),  \n    metrics=[\"accuracy\"]\n)\n\ncallbacks=mycallback()\n\n# Training the model:\n\nprint(\"\\n Model Training :\")\n\nhistory=model.fit(\ntrain_generator,\nsteps_per_epoch=8,\nepochs=50,\nvalidation_data=test_generator,\nvalidation_steps=8,\nverbose=2,callbacks=[callbacks])\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport numpy as np\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array\nimport matplotlib.pyplot as plt\n\n# Assuming `model` is your trained model\n# Load the model here if it's not already loaded\n\n# Get the image path from the user\npath = input(\"Enter image path: \")\n\n# Check if the file exists\nif not os.path.isfile(path):\n    print(\"The specified file does not exist.\")\nelse:\n    # Load the image\n    img = load_img(path, target_size=(300, 300))\n    x = img_to_array(img)\n    x /= 255.0\n    \n    # Expand dimensions to match the model's input shape\n    x = np.expand_dims(x, axis=0)\n    \n    # Predict the class\n    classes = model.predict(x, batch_size=1)\n    \n    # Print the predicted class\n    print(classes[0])\n    if classes[0] > 0.5:\n        print(f\"{os.path.basename(path)} is a dog\")\n    else:\n        print(f\"{os.path.basename(path)} is a cat\")\n\n    # Display the image\n    plt.imshow(img)\n    plt.title(f\"Prediction: {'Dog' if classes[0] > 0.5 else 'Cat'}\")\n    plt.axis('off')\n    plt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Evalute on the test set:\n\nprint(\"\\n Model Evaluation :\")\ntest_loss = model.evaluate(test_generator, verbose=2)\nprint(test_loss)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"\\n Model Prediction :\")\ny_predict=model.predict(test_generator)\ny_predict[:10]\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# compute min & max in the y_prediction:\nprint(f\"the min_value for prediction --->> {np.min(y_predict)} \\n the max_value for prediction --->>> {np.max(y_predict)} \")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plotting training history (accuracy and loss)\nplt.figure(figsize=(12, 6))\n\n# Plot training & validation accuracy values\nplt.subplot(1, 2, 1)\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Model Accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.legend(['Train', 'Test'], loc='upper left')\n\n# Plot training & validation loss values\nplt.subplot(1, 2, 2)\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.legend(['Train', 'Test'], loc='upper left')\n\nplt.tight_layout()\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## End project \n\n* Devloper : AbdalRahman Gameel Ahmed Hebishy\n\n* if you find my Notebook useful upvote me & Leave a comment if you have any Question\n\n* Kaggle works : https://www.kaggle.com/work\n   ","metadata":{}}]}